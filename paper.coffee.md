---
title: Borders & Legitimacy
author: Dave Kinkead
email: d.kinkead@uq.edu.au
status: draft
license: CC-BY-SA
bibliography: /Users/dave/Dropbox/Research/Reading Notes/.library.bibtex
---

> Simultaneously a philosophical argument and a computer simulation, this paper is written in [literate coffeescript](http://coffeescript.org/), allowing the code described by the text to be executed with the command `coffee -l filename`.  The following links outline [installation](http://coffeescript.org/#installation) and [dependency](https://npmjs.org/doc/install.html) requirements.

## Introduction

There are many ways one might justify democracy [^definitions].  A common approach is to point to the desirable outcomes that democratic procedures produce.  Sometimes the desirability of these outcomes is judged according to some independent criteria.  According to these accounts, there is some external standard for measuring the quality of a decision.  Epistemic accounts of democracy like Condorcet's Jury Theorem [@condorcet] or David Estund's Epistemic Proceduralism [@estlund] are like this.  Truth exists independently of our beliefs and democratic processes track the truth, so this gives us reason to value democracy.

Other times, we might judge the quality of democratic outcomes against some agent relative criteria.  Rather than rely on something external, the desirability of a particular result is assessed against some internal standard.  It isn't the collective decisions of democracy that matter _per se_ but how those collective decisions correspond with individual choices.  We see this in utilitarian justifications of democracy where majority voting maximizes the expected utility of voter preferences [@rae].  But one needn't be a utilitarian to employ such an approach - @rousseau for example, argued that majority rule realises the general will of the people and this gives us reasons value it.

And for others still, it is not the content of democratic decision making that matters so much as the effects that democratic processes have on the participants.  This is what @mill had in mind when he argued that democracy transforms the moral character of its participants.  Democratic participation makes good citizens.

Call these accounts of democracy _consequentialist_.

[^definitions]: !!FIX THIS!! The word justification has been employed in a variety of ways within political literature.....By _accounts of democracy_, I mean any normative theory of democracy's value.  Not all accounts of democracy are consequentialist.  Intrinsic accounts of democracy for example, justify political authority without any reference to specific outcomes of the democratic process, and instead appeal to substantive ideals like equality, justice.  Unless explicitly stated, _Democracy_ in this paper refers exclusively those consequentialist conceptions where outcomes do the normative heavy lifting of justifying political authority.

  * * * 

The outcome of any democratic procedure is a function, in part, of who gets to participate in that procedure.  Enfranchising some people rather than others, drawing the political line on a map in one location rather than another, will often result in different outcomes than would have otherwise occurred, even for identical democratic procedures.  Who is included in a particular democracy affects the outcomes of that democracy.

Some democratic processes are deterministic.  People vote according to their belief or preference and the voting procedures employed determines a winning outcome.  This is true for both _naive voting_, where voters believe they alone determine the outcome, as well as _strategic voting_, where voters support a choice other than their sincere preference in an attempt to increase the likelihood of an acceptable outcome [@feddersen1999]. 

In both cases, the outcome of a democratic process is fully a function of who participates in that process.  On one extreme when choices are fully polarised, including or excluding a single voter will change the outcome of a democratic process.  At the other extreme of complete consensus, over 50% of voters would need to be replaced for the outcome to change.

But other democratic processes are indeterministic. This may be because voters themselves don't know how they will vote until the moment they cast their ballot, or because the decision mechanism itself is indeterminate, as in the case of sortition or selection by lottery.  Yet even in these cases, the outcome of a democratic processes remain a function of who is included in that process because changing participants changes the likelihood of particular outcomes.

_Who_ votes determines _what_ is decided.

  * * * 

So when democracy is justified by way of its outcomes, and those outcomes are determined by who is included in the democratic process, the question of _who should be included_ becomes a matter of fundamental importance for those accounts of democracy.

Yet the question of who ought be included in a political association - of how the demos ought be bounded - is frightfully difficult for democratic theory.  Attempting to answer the question of inclusion democratically results in an infinite regress - to vote on who gets to participate in a democracy first requires the identification of some prior group to make this decision, and to identify that prior group democratically we must identify a prior prior group, _ad infinitum_.  

In what has become known as the _Boundary Problem of Democratic Theory_ [^other-names], no account of inclusion is compatible with the various of accounts of democracy [^treatment].  Accounts of inclusion based on the status quo make the matter contingent upon the accidents of history; those based on nationality lack clear and objective criteria; cultural and linguistic salience ignores the reality of multiculturalism; and accounts based on coercion and affected interests are incompatible with the current structure of nation-states.

[^other-names]: A large footnote on who has called this problem what...

[^treatment]: See @whelan1983 for the seminal analysis of the challenges that the Boundary Problem presents as well as more recent work by @dahl1989, @arrhenius2005, @bergström2007, @goodin2007, @miller2009, @agné2010, @abizadeh2012, @schaffer2012, @song2012, and @erman2014.


The question I wish to explore in this paper is _when is the Boundary Problem a problem for consequentialist accounts of democracy_?  Addressing _why_ the Boundary Problem is a problem, or _how_ it might be solved is not the focus of this paper. Rather, I wish to explore the relationship between accounts of inclusion and accounts of democracy and advance three claims that relate to any answer to the question of who the people ought be:

  1.  That accounts of democracy must be compatible with accounts of inclusion.

  2.  That different accounts of democracy require differing, sometimes incompatible accounts of inclusion.

  3.  That different accounts of democracy that have incompatible accounts of inclusion are themselves incompatible.

The first claim advances the existing literature on the Boundary Problem by making the link between inclusion and democracy explicit, thereby placing additional demands on any account of democracy.  Often, political theorists approach the problem of inclusion from a cosmopolitan position, arguing that the question is primarily about justice.  Other times, the concern is related to whether or not an answer is internally consistent with democracy, or whether it actually is a paradox of founding.  Only rarely however, is the link between the problem of inclusion and the value of democratic addressed, and typically this is only implicit.  I will show that any consequential account of democracy's value must be compatible with it's associated claim of democratic inclusion.

The second claim offers something new.  Different accounts of democracy require differing accounts of inclusion for the two to be compatible.  As we shall see, accounts of democracy based on content-independent criteria require different accounts of inclusion to accounts of authority based on content-relative criteria; while content-indifferent accounts of authority can be compatible with both.

Which leads us to the third claim: whenever the differing accounts of inclusion are incompatible with each other, their subsequent accounts of democratic authority must also be incompatible with each other.  Political theorists however, frequently combine these incompatible accounts of democratic authority.  Mill for example justifies democratic rule on the ground that it is more reliable in determining the right decision (a content-independent criteria), takes into consideration the preferences of all (a content-relative criteria), and transforms the moral character of participants (a content-indifferent criteria).

To reiterate, this is not an argument about _how_ or _why_ the Boundary Problem is a problem for democratic theory.  The Boundary Problem raises a number of challenges for democratic theory but here I focus exclusively on the Boundary Problem as it relates to claims of democratic legitimacy.  As such, I don't seek to explain who should be included in the demos, nor what principles might guide us to an answer. Rather, it is an examination of _when_ the Boundary Problem is a problem.  This paper is concerned with the relationship between accounts of democratic inclusion and accounts of democratic authority.  It is an argument about how the Boundary Problem challenges the legitimacy of democratic authority by specifying the conditions under which inclusion affects democratic outcomes.


## Methodology

- explain the problem
- justify simulation
- conceptual modelling not reality modelling
- testing theoretical claims for coherence

## A Model of Democracy

- explain the model

## Content Independent Accounts

- explain the simulation
- analyise the results

## Content Relative Accounts

- explain the simulation
- analyise the results

## Content Indifferent Accounts

- explain the simulation
- analyise the results

## Conclusion

- explain the simulation
- analyise the results

---




## A Model of Democracy

How then can we examine the relationship between democratic inclusion and democratic authority - how changing the makeup of the demos changes the outcome of democratic processes? As philosophers, deductively reasoning from first principles or mutually agreed upon premises is a time-honoured approach.  We might first postulate some axioms of human nature and essential conditions of democracy before then demonstrating that certain states of affairs are necessary or possible, entailed or contradictory.

The obvious flaw with this approach however is that many critical elements of political science, political theory, and political philosophy are questions of empiric fact.....!!explain!!....

Given the empiric nature of the investigation, we could employ a scientific approach.  We might observe how actual democratic polities form and how different compositions of polities lead to different democratic outcomes.  But the complexity of human systems makes this all but impossible.  The lack of adequate sample sizes when using democratic states as relata, the non-linearity that arises from numerous feedback loops, and the inability to hold variables fix 'in the wild' impose severe limits on our causal modelling and explanations that continue to bedevil the social sciences.

Although rarely used in philosophy, a third approach that offers considerable insight into this problem is computer simulation.  Typically, simulations are used to make predictions about the real world.  They attempt to model reality as accurately as possible before showing how changes in inputs lead to changes in the simulation.  The weakness of this approach however, and perhaps a key reason for the lack of simulation in philosophy, concerns the fidelity of the model with reality.  If the model fails to accurately depict reality, then any inferences from the model will offer little insight into reality.  And given the empiric challenges of modelling complex human systems discussed above, the problems of simulating political reality look overwhelming.

But another approach would be to simulate _theory_.  All theories are abstractions of reality, so simulating theory simply formalises those abstractions.... This type of simulation can be thought of as a coherence constrain on particular theories. By making the assumptions and abstractions of a theory explicit in code, we can see if the predictions and claims of that theory are entailed or at least made probable.  We can show that a theoretical model is coherent even if we can't show that the theory's assumptions do in fact hold true in reality.

What follows then is both a description of a model of democracy as well as a simulation of that model.  It attempts to capture the key claims of consequentialist accounts of democracy and explore how changing the make up of the polity affects the democratic processes of that polity.  The simulation process begins by defining a simple model of democracy consisting of naive voters populating some political space.  Methods of inclusion and voting are then defined.

Next, three types of consequentialist accounts of democracy - content-independent, content-relative, and content-indifferent - are formalised and simulated in the model over a wide variety of input values.  Finally, the relationship between democratic inclusion and democratic outcomes is explored by examining how different compositions of agents lead to different results. 

A form of literate programming [^lit], this paper embeds executable source code within the description of the model.  Simulation code is indicated by `indented code blocks`.  The reader need not understand the embedded code or coffeescript syntax however, in order to understand the simulation.  The code, it's purpose, and function will be fully explained in the surrounding text. It's presence serves to formalise the assumptions of the model in much the same way as one might include mathematical symbolism to formalise a proof, and to promote reproducibility and testability of the research herein.

[^lit]: Note about literate programming

The model comprises three distinct conceptual entities: a `Political Space` representing the problem domain, `Political Agents` who are distributed across the space, and partitions of the space that group agents into political units or `Polities`. 

An agent represents a political actor or citizen.  They are simple folk who hold a single discrete value representing a belief, preference, character trait, or virtue - right or wrong, Republican or Democrat, chocolate or vanilla, virtuous or iniquitous. This is represented formally in code as:


    class Agent
      constructor: (@belief) ->


Agents exist within a space which represents the problem domain.  This can be any conceptual space that needs to be partitioned in some way. - the world to be divide somehow into countries, countries into provinces, players into teams, or believers into congregations.  

A space is constructed by specifying an agent profile of how many agents hold which belief, preference, or virtue.  These belief are stipulative.  They are defined at the start of the simulation and form its parameters.  For example, an agent profle of  `{ 'chocolate': 400, 'vanilla': 600 }` would create a space with 400 agents whose preference is chocolate and 600 whose preference is vanilla.


    class Space
      constructor: (agent_profile) ->
        @agents = []
        for belief, believers of agent_profile
          for n in [1..believers]
            @agents.push new Agent(belief)


Agents are distributed across the space in some way according to their belief.  This distribution could be perfectly uniform, with agents evenly spread across the space; or agents could be tightly clustered so that all agents of a similar belief are grouped together.

Agents in our space will be distributed according to a cluster factor which determines the proximity of agents holding similar beliefs with one another.  A factor of `1.0` will result in a highly clustered space with all like agents grouped together, while `0.0` will result in a uniform random distribution of agent belief.


    Space::distribute = (cluster=0.0) ->
      quota = @agents
      @agents = []
      while quota.length > 0
        limit = Math.round( Math.random() * quota.length * (1-cluster) )
        @agents = @agents.concat quota.splice limit, 1


Spaces are be partitioned into polities.  A polity represents a unit of political association that holds some degree of sovereignty regarding specific issues, such as a nation-state, province, or local council.  How we partition a space - how we decide who will be included in which political association - forms the crux of the Boundary Problem.

There are many ways to partition a political space.  Amongst accounts of democratic inclusion we find proposals to group agents according to nationality, cultural or linguistic salience, degree of economic or social interdependence, by who is affected by a policy or issue, or even to not partition at all. 

While numerous accounts of inclusion exist in political theory, the combination of actual possible partitions of any space is orders of magnitude greater [^combos].  Given this myriad of potential methods of inclusion, a stochastic algorithm to divide the space into different polities will be used to generate a sample of partitions.  This allows the simulation to be agnostic with regards to the specific account of democratic inclusion while capturing a wide variety of agent compositions.

[^combos]: The possible number of different partitions is the sum of binomial coefficients of agents and the number groups they are partitioned into.  This increases exponentially as the number of agents and groups increases, making a simulating all possible partitions within a reasonable time frame is beyond the capacity of desktop computing.

The partitioning algorithm recursively divides the largest polity of the space at a random point until the desired number of polities have been produced - each characterised by a differing number and composition of agents. 


    Space::partition = (k) ->
      @polities = [@agents]
      while k > 1
        k = Math.min k, @agents.length
        polity = @polities.shift()
        cut = Math.floor( Math.random() * (polity.length - k) ) + 1
        @polities.push polity[...cut]
        @polities.push polity[cut..]
        @polities.sort (a,b) -> b.length-a.length
        k--
      this


The decision procedure used by our model democracy will be a naive majority vote on a binary issue, as this is the simplest decision mechanism to model.  Agents vote sincerely and deterministically according to their belief.


    vote = (polity) ->
      votes = {}
      for agent in polity
        if votes.hasOwnProperty agent.belief then votes[agent.belief]++ else votes[agent.belief] = 1
      max = Math.max.apply null, (num for belief, num of votes)
      votes.winner = belief for belief, num of votes when num is max
      votes


With our model defined, the relationship between democratic authority and democratic inclusion can now be explored by running Monte Carlo simulations [^monte] of the model for various combinations of agent, clusterings, and partitions.  At the beginning of each simulation, a space is created with a fixed agent profile, clustering factor, and polity number.  During each run, the space is partitioned into the desired number of polities which then vote, with the results being recorded for statistical analysis.  

The partion-vote-measure loop is repeated 1000 times, generating in a probability density function of the the voting result for each of the belief-cluster-partion tuples.  These results are then assessed against three classes of consequentialist accounts of democracy to examine the conditions under which democratic inclusion affects democratic authority.

[^monte]: Monte Carlo simulations are class of computational algorithms that rely on statistical sampling from repeated simulation trials to generate numerical results. [see @fishman1996 for a full treatment of their use in computer simulation].


## Content Independent Outcomes

One common justifications for democratic authority is epistemic - that democracy has instrumental value as a truth tracking processes.  Some of these epistemic accounts are relatively simple and Condorcet's Jury Theorem is one such example. Given a better than even chance of any voter being correct on some issue, then the likelihood of a majority vote being being correct approaches certainty as the number of voters increases [see @list2001].  

Others, like @estlund2009's Epistemic Proceduralism, are more nuanced.  Rather than valuing democracy on the basis of the outcome of a specific vote, democracy has legitimacy because much like a jury, its decision processes have a tendency to make produce correct decisions. Even when the majority is wrong on a particular matter, the majority decision is morally binding as long as majority voting is the more reliable procedure than its alternatives.

While different, all epistemic accounts rely on the claim that democratic procedures, on average, are better at determining the correct result than alternate ones. Further more, these results are correct _independently_ of the decision procedure used.  

This type of justification obviously requires some way of comparing the epistemic performance of different decision procedures and one intuitive way to do this is to assess them against some base line metric.  An obvious candidate for such a metric is the likelihood that any randomly selected voter holds the correct belief or votes correctly - what I will call the _epistemic base rate_ of a political space.

We can call the difference between the epistemic performance of a decision procedure and the epistemic base rate a procedure's _epistemic virtue_.  If the epistemic base rate - the likelihood of a randomly selected voter being correct - was 51%, and the likelihood of a majority decision of 1000 voters being correct was 99%,  then the epistemic virtue of the process is the difference between the two - 48% - whereas a coin toss has no epistemic virtue. (see @estlund1997 for a deeper discussion of the mathematics behind Condorcet's Theorem).

In our simulation, the epistemic virtue of a simple majority vote can be measured as the frequency based probability that a polity votes correctly given the initial conditions of the space.  During each trial, the number of polities that voted correctly is measured and the impact of differing partitions assessed.  The correct answer to the question our agents vote on is known in advance because we stipulate it when we create agents with either `right` or `wrong` belief.


    Space::virtue = () ->
      correctVotes = 0
      for polity in @polities
        election = vote polity
        correctVotes += 1 if election.winner is 'right'
      correctVotes / @polities.length


Running a Monte Carlo simulation hundreds of thousands of times for a range of partition numbers (5 to 25), cluster factors (0.0 to 1.0) and epistemic base rates (0.51 to 0.75) yields a probability distribution of the expected correct majority vote for each base-rate-partition-cluster tuple.

We can examine the results from any perspective of the tuple.  In the graph below, we see the impact of repartitioning on the epistemic virtue of a polity with an epistemic base rate of 0.6 from the perspective of clustering (each line representing the number of polities the space was partitioned into).  

![Epistemic virtue by cluster factor](graphs/epi-600-c.png)

The likelihood of any randomly selected voter in the space being correct is 0.6. When agents are uniformly distributed across the space by belief (ie no clustering of agent belief is present), the epistemic virtue of majority voting  - the likelihood that the majority vote of any polity is the correct choice - is very high (0.85-0.97).  This quickly deteriorates as clustering of agent belief increases however, with no epistemic virtue of majority voting evident once agent clustering reaches 0.5.  This hold true for all levels of partition numbers and epistemic base rates > 0.51.

![Epistemic virtue by partition number](graphs/epi-600-p.png)

Examining the same data from the perspective of partition number, we see little impact of partition number on epistemic virtue for higher cluster factors, and only limited impact for low levels of clustering, concordant with Condorcet's Theorem [^explain].  This relationship holds for all epistemic base rates between 0.51 and 0.99.

[^explain]: Condorcet's Jury Theorem posits that the likelihood of majority rule selecting the correct outcome increases as the number of voters increases (assuming voters have an independent better than even chance of voting correctly).  The 0 cluster line deceases as the same number of voters in the space is partitioned into increasing numbers of polities.

These results indicate that the epistemic virtue of majority voting is dependent not only on individual agent belief having a greater than 50% likelihood of being correct, but also on how those agent belief are distributed across the political space.  A key stipulation of the Jury Theorem is that there is a better than average chance of any voter being correct - we might call this the _competency requirement_.  This simulation shows that when clustering of agent belief is present, even if the comeptency requirement is true for the space as a whole, it is not necessarily true for every parition of that space.  Furthermore, as clustering of agent belief across the space increases, the likelihood that every partition of the space satisfies the competency criteria decreases.

The relationship between content-independent justifications of democracy and democratic inclusion now becomes clearer. Epistemic justifications of democracy require accounts of inclusion that ensure that:

  1. Polities are sufficiently large for the Condorcet effect to emerge.

  2. Each polity can satisfies the competency requirement even when the political space does.

  - need to add that polities must be heterogeneous when the space is homogeneous

Where we draw the boundaries of our democracies is irrelevant for content-independent accounts of democracy when the distribution of voter belief is uniform. All accounts are democratic inclusion are compatible with accounts of democratic authority in the case - any one will do.

But where we draw boundaries of our democracies becomes critically important for these accounts of democratic authority when the distribution of voter belief is clustered. In this case, any compatible account of democratic inclusion will need to demonstrate that each polity statisfies the competency requirement for epistemic justifications.  We can summarise this insight by stating that the Boundary Problem only becomes a problem for content-independent justifications of democracy when homogeneity of voter belief is high within polities but low between them.


##  Content Relative Outcomes

Not all consequentialist accounts of democracy are epistemic however.  Utilitarians justify democracy on the grounds that it promotes the greatest happiness.  Majority voting maximizes the expected utility of voter preferences when each individual has an equal chance of preferring each of two alternatives [@rae].  But one needn't be a card carrying utilitarian to employ such an approach.  @rousseau argued that majority rule realises the general will of the people and this gives us reasons to obey, while social choice theorists hold that majority voting realises individual choice when collectively binding decisions must be made (@may1952).

While these accounts of democracy are considerably different, they all share a similarity in that the value of democracy stems from some content-relative criteria - of fidelity between individual preference and collective outcome.  It is not the contents of the outcome of a democratic process that matters per se, but rather how well this collective outcome matches the wants, preferences, or intent of individual participants.

We can judge these content-relative outcomes by defining the fidelity of a democratic process as the likelihood that an individual's preference is the same as, or compatible, with the majority outcome.  Formalising fidelity as individual-collective choice equivalence we get: 
    
    
    Space::fidelity = () ->
      winners = 0
      population = 0
      for polity in @polities
        election = vote polity
        for key, val of election
          winners += val if key is election.winner
          population += val unless key is 'winner'
      winners / population 


Running the same Monte Carlo simulation for the same variables as for the epistemic simulation yields a different set of results to those of the content-independent one.  Below, we see the fidelity of individual preference to majority vote for a distribution of agents with a 60:40 preference for some choice A or B over a range of clustering and partition variables, viewed by degree of clustering.

![Preference realisation by cluster factor](graphs/pref-600-c.png)

Again, when viewed by degree of clustering, the impact of re-partitioning on preference realisation is stark.  When agents are uniformly distributed by preference across the space, the likelihood of an individual's preference being realised by majority vote is identical to that of any two random agents preference being the same i.e. the preference base rate.

As clustering of agent preferences increases however, the fidelity between individual and majority preference increases significantly. At its most extreme, there is near certainty that individual preference will be realised by a majority vote when the distribution of agents across the political space is fully clusters i.e. agents are completely segregated by preference.  This relationship holds for all preference base rates.

In contrast with the epistemic simulation of democracy however, the impact of agent clustering is reversed.  Majority voting has the greatest likelihood of fidelity with individual preference, and therefore greatest value from a content-relative perspective, when agents are highly clustered.  This contrasts sharply with the content-independent perspective where the greatest epistemic value of majority voting was found with a completely uniform agent distribution.

![Preference realisation by partion number](graphs/pref-600-p.png)

The number of polities a space is partitioned into plays only a limited role in individual-majority preference fidelity. As the space is partioned into increasing numbers of polities, fidelity increases slightly when preference are highly clustered, but the influence of partition number is significantly less than the impact of preference clustering.

The key implication from this analysis is that accounts of democratic authority based on preference realisation and the fidelity of individual with group preference require an account of democratic inclusion that ensures that: 

1. Polities are sufficiently small.
2. Voters are sufficiently homogeneous in preference.

Restated, where we draw political boundaries is irrelevant for content-relative accounts of democracy if the distribution of voters by preference is highly clustered.  Where we draw boundaries is very important however, when the distribution of voters by preference is uniform.  The Boundary Problem only becomes a problem for content-relative justifications of democracy when homogeneity of voter preferences is low within polities but high between them.


## Content Indifferent Outcomes


!! This part is still under development...

A third type of consequential justification of democracy is that transforms the moral character of participants.

Talk about Mill & Rousseau...


    Space::character = () ->
      correctVotes = 0
      for polity in @polities
        election = vote polity
        correctVotes += 1 if election.winner is 'right'
      correctVotes / @polities.length


## Conclusion

!! Yes, I need to rewrite this conclusion - do not bother reading yet....

While I've only examined two accounts of democratic authority from the wide array of accounts offered by political theorists, the data from the simulation allows us to make the number inferences.

Firstly, on both epistemic and strategic accounts of democracy, the method of inclusion used to bound the demos has a clear impact on the outcome of a democratic process, in this case simple majority voting.  Given a some fixed distribution of agents over a political space, how we partition that space has a causal effect on the the outcomes of a voting process within that space.

Secondly, the impact of the inclusion method is not just different but contradictory for epistemic and perference realisation accounts of democratic authority.  Epistemicly accounts of authority require accounts of inclusion that generate large polities with uniformly distributed agent beliefs.  Preference realisation accounts of authority on the other hand, require accounts of inclusion that generate small polities with highly clustered agent preference.

Thirdly, the conflicting nature of the required accounts of inclusion for epistemic and perference realisation accounts of authority mean that these accounts are incompatible with each other.  One cannot maintain that democratic authority is justified because it has both epistemic virtue and realises individual preferences.  

Many justifications of democracy employ this type of hybrid approach.  Mill for example, justifies democracy on both epistemic and strategic grounds, arguing that democratic authority is legitimate because it generally reaches good decisions and is forced to consider the preferences of all citizens.  The incompatibility of accounts of inclusion that these approaches require however, demonstrates that this type of justification is incoherent.

In other words...

- any consequentialist account of democracy must be compatible with accounts of democratic inclusion 
- different accounts of authority require differing, sometimes incompatible accounts of inclusion
- different accounts of authority that have incompatible accounts of inclusion are themselves incompatible


## Epilogue

A number of helper functions are necessary for the simulation to work, as well as initiate the Monte Carlo runs.  

!! I can move a lot of the in paper code down to here...



    fs       = require 'fs'
    sum      = (arr) -> arr.reduce (a,b) -> a + b
    ave      = (arr) -> sum(arr) / arr.length
    variance = (arr) ->
      mean = ave(arr)
      (arr.reduce ( (a,b) -> a + (mean-b)*(mean-b)), 0) / arr.length
    stdev    = (arr) -> Math.sqrt( variance arr)


    simulateDemocracy = (account, agents, partitions, clustering, trials) ->
      space = new Space agents
      space.distribute clustering
      results = { 'a': agents, 'p': partitions, 'c': clustering, 'trials': [] }
      for trial in [1..trials]
        results.trials.push space[account]( space.partition partitions )
      results

    save = (type, results) ->
      fs.writeFile "graphs/#{type}.json", JSON.stringify( results, null, 2 ) , (err) ->
        if err then console.log err

    runEpistemicSimulation = () ->
      results = []
      for e in [0..5]
        e = 500 + e*50
        e = 510 if e is 500
        for p in [0..5]
          p = (p+1)*5
          for c in [0..5]
            c = c/5
            es = simulateDemocracy( 'virtue', {'right': e, 'wrong': 1000-e}, p, c, 1000 )
            results.push { e: e, p: p, c: c, value: ave(es.trials).toFixed(15) }
            process.stdout.write "Running #{results.length * 1000} epistemic trials\r"
      save 'epistemic', results
      
      
    runPreferenceSimulation = () ->
      results = []
      for f in [0..5]
        f = 500 + f*100
        for p in [0..5]
          p = (p+1)*5
          for c in [0..5]
            c = c/5
            ps = simulateDemocracy( 'fidelity', {'chocolate': f, 'vanilla': 1000-f}, p, c, 1000 )
            results.push { f: f, p: p, c: c, value: ave(ps.trials).toFixed(15) }
            process.stdout.write "Running #{results.length * 1000} preference trials\r"
      save 'preference', results
    
    module.exports = { simulate: simulateDemocracy }

Finally, we capture terminal inputs to start up the simulation.  To run the simulation of epistemic democracy, use the command `coffee paper.coffee.md epsitemic`.  This will execute the code embedded described in the paper above.


    process.argv.forEach (val, index, array) ->
      runEpistemicSimulation() if val is 'epistemic'
      runPreferenceSimulation() if val is 'preference'
